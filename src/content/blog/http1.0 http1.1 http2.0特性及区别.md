---
title: "http1.0 http1.1 http2.0特性及区别"
date: "2021-01-25 15:19"
draft: false
tags:
- http
---


## http1.0特性
- 无连接
- 无状态
### 无连接
#### 无法复用链接
client与server之间每次通信都会开辟一条新的通道，会执行三次握手四次挥手，导致网络效率降低
#### 对头阻塞
请求是同步的，只能等上一次请求结束之后，才能进行下一次请求
### 无状态

- 没有身份验证和状态记录
- 可以使用session/cookies存储验证信息

## http1.1特性
为了解决http1.0的缺陷，http1.1出现了

- 长连接： 新增connection字段，可以设置keep-alive网络链接一直不断开
- 管道化： 可以在上次的响应没来之前，开始下一次请求
- 缓存： 新增cache-control字段，如果开启了缓存，多次的同一请求，会优先从缓存中读取
- 断点传输
### 长连接
此次通信完毕后，网络通道可以不关闭，下次继续使用
### 管道化
在以前http1.0没有管道化的情况下
```
请求1=>响应1=>请求2=>响应2=>请求3=>响应3
```
http1.1管道
```
请求1=>请求2=>请求3=>响应1=>响应2=>响应3
```
也就是说可以在响应之前，继续下次的请求，但是依然会有对头阻塞的问题，响应是按顺序返回的
### 缓存
这个比较复杂了，根据服务端不同的配置，有不同的缓存策略。大概就是客户端在反复请求同一接口时，会在缓存中读取数据
### 断点传输
在上传/下载资源较大的时候，可以开启断点传输策略，暂停上传、暂停下载功能就是基于此实现的
在 Header 里两个参数实现的，客户端发请求时对应的是 Range 服务器端响应时对应的是 Content-Range

## http2.0

- 二进制分帧
- 多路复用
- 头部压缩
- 服务器主动推送
### 多路复用
这个是为了解决http1.1的队头阻塞（并不能解决TCP的阻塞）。基于二进制分帧，并且给每个帧打上流的 ID 去避免依次响应的问题，对方接收到帧之后根据 ID 拼接出流，这样就可以做到乱序响应从而避免请求时的队首阻塞问题。
但是 TCP 层面的队首阻塞是 HTTP/2 无法解决的（HTTP 只是应用层协议，TCP 是传输层协议），TCP 的阻塞问题是因为传输阶段可能会丢包，一旦丢包就会等待重新发包，阻塞后续传输

